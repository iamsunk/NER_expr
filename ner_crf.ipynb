{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a1/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/a1/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "class MyPrettyPrinter(pprint.PrettyPrinter):\n",
    "\tdef format(self, _object, context, maxlevels, level):\n",
    "\t\tif isinstance(_object, unicode):\n",
    "\t\t\treturn \"'%s'\" % _object.encode('utf8'), True, False\n",
    "\t\telif isinstance(_object, str):\n",
    "\t\t\t_object = unicode(_object,'utf8')\n",
    "\t\t\treturn \"'%s'\" % _object.encode('utf8'), True, False\n",
    "\t\treturn pprint.PrettyPrinter.format(self, _object, context, maxlevels, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(data):\n",
    "    sentList = []\n",
    "    with open(data) as f:\n",
    "        words = []\n",
    "        for line in f:\n",
    "            atts = line.strip().split(\"\\t\")\n",
    "            if len(atts)<=1:\n",
    "                sentList.append(words)\n",
    "                words=[]\n",
    "                continue\n",
    "            no,word,tag = atts\n",
    "            words.append((word,tag))\n",
    "            \n",
    "    return sentList\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "where=\"/Users/a1/Source/play_data/nlp-challenge/missions/ner/data/train/train_data\"\n",
    "tagData = loadData(where)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\xeb\\xb9\\x84\\xed\\x86\\xa0\\xeb\\xa6\\xac\\xec\\x98\\xa4', 'PER_B'),\n",
       " ('\\xec\\x96\\x91\\xec\\x9d\\xbc', 'DAT_B'),\n",
       " ('\\xeb\\xa7\\x8c\\xec\\x97\\x90', '-'),\n",
       " ('\\xec\\x98\\x81\\xec\\x82\\xac\\xea\\xb4\\x80', 'ORG_B'),\n",
       " ('\\xea\\xb0\\x90\\xed\\x98\\xb8', 'CVL_B'),\n",
       " ('\\xec\\x9a\\xa9\\xed\\x87\\xb4,', '-'),\n",
       " ('\\xed\\x95\\xad\\xeb\\xa3\\xa1', '-'),\n",
       " ('\\xec\\x95\\x95\\xeb\\xa0\\xa5\\xec\\x84\\xa4', '-'),\n",
       " ('\\xec\\x9d\\x98\\xec\\x8b\\xac\\xeb\\xa7\\x8c', '-'),\n",
       " ('\\xea\\xb0\\x80\\xec\\x9c\\xa8', '-')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in tagData]\n",
    "y_train = [sent2labels(s) for s in tagData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test= X_train[80000:]\n",
    "y_test = y_train[80000:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PER_B',\n",
       " 'DAT_B',\n",
       " '-',\n",
       " 'ORG_B',\n",
       " 'CVL_B',\n",
       " 'NUM_B',\n",
       " 'LOC_B',\n",
       " 'EVT_B',\n",
       " 'TRM_B',\n",
       " 'TRM_I',\n",
       " 'EVT_I',\n",
       " 'PER_I',\n",
       " 'CVL_I',\n",
       " 'NUM_I',\n",
       " 'TIM_B',\n",
       " 'TIM_I',\n",
       " 'ANM_B',\n",
       " 'DAT_I',\n",
       " 'FLD_B',\n",
       " 'ORG_I',\n",
       " 'MAT_B',\n",
       " 'MAT_I',\n",
       " 'AFW_B',\n",
       " 'LOC_I',\n",
       " 'AFW_I',\n",
       " 'PLT_B',\n",
       " 'FLD_I',\n",
       " 'ANM_I',\n",
       " 'PLT_I']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test\n",
    "y_pred = crf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PER_B',\n",
       " 'DAT_B',\n",
       " '-',\n",
       " 'ORG_B',\n",
       " 'CVL_B',\n",
       " 'NUM_B',\n",
       " 'LOC_B',\n",
       " 'EVT_B',\n",
       " 'TRM_B',\n",
       " 'TRM_I',\n",
       " 'EVT_I',\n",
       " 'PER_I',\n",
       " 'CVL_I',\n",
       " 'NUM_I',\n",
       " 'TIM_B',\n",
       " 'TIM_I',\n",
       " 'ANM_B',\n",
       " 'DAT_I',\n",
       " 'FLD_B',\n",
       " 'ORG_I',\n",
       " 'MAT_B',\n",
       " 'MAT_I',\n",
       " 'AFW_B',\n",
       " 'LOC_I',\n",
       " 'AFW_I',\n",
       " 'PLT_B',\n",
       " 'FLD_I',\n",
       " 'ANM_I',\n",
       " 'PLT_I']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a1/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/a1/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9897225089618146"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          -      0.990     0.997     0.994     81348\n",
      "      DAT_B      0.989     0.979     0.984      2874\n",
      "      MAT_B      1.000     0.773     0.872        22\n",
      "      DAT_I      0.971     0.982     0.977       936\n",
      "      MAT_I      1.000     1.000     1.000         3\n",
      "      PER_B      0.994     0.983     0.988      4761\n",
      "      PER_I      1.000     0.995     0.997       596\n",
      "      AFW_B      0.983     0.943     0.963       491\n",
      "      AFW_I      0.969     0.995     0.982       191\n",
      "      TIM_B      0.979     0.974     0.976       380\n",
      "      TIM_I      0.979     0.968     0.974        95\n",
      "      FLD_B      0.991     0.863     0.922       255\n",
      "      FLD_I      1.000     0.889     0.941         9\n",
      "      PLT_B      1.000     0.864     0.927        22\n",
      "      PLT_I      0.000     0.000     0.000         0\n",
      "      ANM_B      0.977     0.954     0.966       720\n",
      "      ANM_I      1.000     1.000     1.000         5\n",
      "      LOC_B      0.995     0.971     0.983      2377\n",
      "      LOC_I      1.000     1.000     1.000        26\n",
      "      ORG_B      0.993     0.986     0.989      4701\n",
      "      ORG_I      0.996     0.993     0.995       560\n",
      "      TRM_B      0.990     0.946     0.968      2177\n",
      "      TRM_I      0.978     0.992     0.985       357\n",
      "      NUM_B      0.992     0.977     0.984      6178\n",
      "      NUM_I      0.950     0.975     0.962       956\n",
      "      CVL_B      0.993     0.965     0.979      6287\n",
      "      CVL_I      0.989     0.997     0.993       376\n",
      "      EVT_B      0.977     0.962     0.970      1252\n",
      "      EVT_I      0.976     0.985     0.981       795\n",
      "\n",
      "avg / total      0.990     0.990     0.990    118750\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a1/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/a1/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
